{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/ml-facilito/blob/main/notebooks/Deep_Learning_Clase_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6jO_1gISKxk"
      },
      "source": [
        "# Deep Learning 101 - Clase 1  üß†\n",
        "\n",
        "> **Descripci√≥n:** Cuaderno de contenidos (I) sobre introducci√≥n a _deep learning_ para el Bootcamp de Machine Learning con C√≥digo Facilito, 2023-2025. <br>\n",
        "> **Autor:** [Rodolfo Ferro](https://github.com/RodolfoFerro) <br>\n",
        "> **Contacto:** [X](https://twitter.com/rodo_ferro) / [Instagram](https://www.instagram.com/rodo_ferro/)\n",
        "\n",
        "\n",
        "## Contenido\n",
        "\n",
        "### Secci√≥n I\n",
        "\n",
        "1. Brief hist√≥rico\n",
        "2. Unidad Umbralizaci√≥n Lineal (TLU)\n",
        "3. Activaci√≥n y bias ‚Äì El perceptr√≥n\n",
        "\n",
        "### Secci√≥n II\n",
        "\n",
        "4. Aprendizaje en neuronas\n",
        "5. Entrenamiento de una neurona\n",
        "6. Predicciones\n",
        "\n",
        "### Secci√≥n III ‚Äì Tarea\n",
        "\n",
        "7. El dataset a utilizar\n",
        "8. Preparaci√≥n de los datos\n",
        "9. Creaci√≥n del modelo\n",
        "10. Entrenamiento del modelo\n",
        "11. Evaluaci√≥n y predicci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVG2PnSEtQN"
      },
      "source": [
        "## **Secci√≥n I**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPk1Rkc4FZ5g"
      },
      "source": [
        "### **Breve historia de las redes neuronales**\n",
        "\n",
        "Podr√≠amos decir que la historia se remonta a dar un inicio con el modelo neuronal de McCulloch y Pitts de 1943, la **Threshold Logic Unit (TLU)**, o **Linear Threshold Unit**,‚Äã que fue el primer modelo neuronal moderno, y ha servido de inspiraci√≥n para el desarrollo de otros modelos neuronales. (Puedes leer m√°s [aqu√≠](https://es.wikipedia.org/wiki/Neurona_de_McCulloch-Pitts).)\n",
        "\n",
        "Posterior a los TLU, se la historia se complementa con el desarrollo de un tipo de neurona artificial con una **funci√≥n de activaci√≥n**, llamada **perceptr√≥n**. √âsta fue desarrollada entre 1950 y 1960 por el cient√≠fico **Frank Rosenblatt**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uehq48zoSocy"
      },
      "source": [
        "### **Entonces, ¬øqu√© es una neurona artificial?**\n",
        "\n",
        "Una neurona artificial es una funci√≥n matem√°tica que concevida como un modelo de neuronas biol√≥gicas. (Puedes leer un poco m√°s [aqu√≠](https://en.wikipedia.org/wiki/Artificial_neuron).)\n",
        "\n",
        "El modelo general de una **neurona artificial** toma varias **entradas** $x_1, x_2,..., x_n $ y produce una **salida**. Se propuso que las entradas tuviesen **pesos** asciados $w_1, w_2, ..., w_n$, siendo √©stos n√∫meros reales que podemos interpretar como una expressi√≥n de la importancia respectiva para cada entrada de informaci√≥n para el c√°lculo del valor de salida de la neurona. La salida de la neurona, $0$ o $1$, est√° determinada con base en que la suma ponderada,\n",
        "\n",
        "$$\\displaystyle\\sum_{j}w_jx_j,$$\n",
        "\n",
        "<!-- $\\textbf{w}_{Layer}\\cdot\\textbf{x} =\n",
        "\\begin{bmatrix}\n",
        "w_{1, 1} & w_{1, 2} & \\cdots & w_{1, n}\\\\\n",
        "w_{2, 1} & w_{2, 2} & \\cdots & w_{2, n}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "w_{m, 1} & w_{m, 2} & \\cdots & w_{m, n}\\\\\n",
        "\\end{bmatrix} \\cdot\n",
        "\\begin{bmatrix}\n",
        "x_1\\\\\n",
        "x_2\\\\\n",
        "\\vdots\\\\\n",
        "x_n\n",
        "\\end{bmatrix}$ -->\n",
        "\n",
        "(para $j \\in \\{1, 2, ..., n\\}$ ) sea menor o mayor que un **valor l√≠mite** que por ahora llamaremos **umbral**. (Aqu√≠ comenzamos con la formalizaci√≥n de lo que es un TLU y c√≥mo funciona.)\n",
        "\n",
        "Visto de otro modo, una neurona artificial puede interpretarse como un sistema que toma decisiones con base en la evidencia presentada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q33kCpXyFgJ_"
      },
      "source": [
        "#### **Implementemos una TLU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLBMuek3lBHd"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Primero creamos nuestra clase TLU\n",
        "class TLU():\n",
        "    def __init__(self, inputs, weights):\n",
        "        \"\"\"Class constructor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of input values.\n",
        "        weights : list\n",
        "            List of weight values.\n",
        "        \"\"\"\n",
        "\n",
        "        self.inputs = None # TODO: np.array <- inputs\n",
        "        self.weights = None # TODO: np.array <- weights\n",
        "\n",
        "    def predict(self, threshold):\n",
        "        \"\"\"Function that operates inputs @ weights.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        threshold : int\n",
        "            Threshold value for decision.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Inner product of data\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t42O74IdmKIw"
      },
      "source": [
        "# Now, we need to set inputs and weights\n",
        "inputs, weights = [], [1, 1, 1]\n",
        "\n",
        "questions = [\n",
        "    \"¬∑ ¬øCu√°l es la velocidad? \",\n",
        "    \"¬∑ ¬øRitmo cardiaco? \",\n",
        "    \"¬∑ ¬øRespiraci√≥n? \"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    i = int(input(question))\n",
        "    # w = int(input(\"¬∑ Y su peso asociado es... \"))\n",
        "    inputs.append(i)\n",
        "    # weights.append(w)\n",
        "    print()\n",
        "\n",
        "threshold = int(input(\"¬∑ Y nuestro umbral/l√≠mite ser√°: \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHjy-k33oNFm"
      },
      "source": [
        "tlu = None # TODO Instantiate TLU\n",
        "None # TODO Apply decision function with threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUCCwUG6DgCX"
      },
      "source": [
        "### **Bias y funciones de activaci√≥n ‚Äì El perceptr√≥n**\n",
        "\n",
        "_Antes de continuar, introduciremos otro conceptos, el **bias** y la **funci√≥n de activaci√≥n**._\n",
        "\n",
        "La operaci√≥n matem√°tica que realiza la neurona para la decisi√≥n de umbralizaci√≥n se puede escribir como:\n",
        "\n",
        "$$ f(\\textbf{x}) =\n",
        "  \\begin{cases}\n",
        "    0 & \\text{si $\\displaystyle\\sum_{j}w_jx_j <$ umbral o threshold} \\\\\n",
        "    1 & \\text{si $\\displaystyle\\sum_{j}w_jx_j \\geq$ umbral o threshold} \\\\\n",
        "  \\end{cases}$$\n",
        "\n",
        "donde $j \\in \\{1, 2, ..., n\\}$, y as√≠, $\\textbf{x} = (x_1, x_2, ..., x_n)$.\n",
        "\n",
        "De lo anterior, podemos despejar el umbral y escribirlo como $b$, obteniendo:\n",
        "\n",
        "$$ f(\\textbf{x}) =\n",
        "  \\begin{cases}\n",
        "    0 & \\text{si $\\displaystyle\\sum_{j}w_jx_j + b < 0$} \\\\\n",
        "    1 & \\text{si $\\displaystyle\\sum_{j}w_jx_j + b > 0$} \\\\\n",
        "  \\end{cases}$$\n",
        "\n",
        "donde $\\textbf{x} = (x_1, x_2, ..., x_n)$ y $j \\in \\{1, 2, ..., n\\}$.\n",
        "\n",
        "Esto que escribimos como $b$, tambi√©n se le conoce como **bias**, y describe *qu√© tan susceptible la red es a __dispararse__*.\n",
        "\n",
        "Curiosamente, esta descripci√≥n matem√°tica encaja con una funci√≥n de salto o de escal√≥n (funci√≥n [_Heaviside_](https://es.wikipedia.org/wiki/Funci%C3%B3n_escal%C3%B3n_de_Heaviside)), que es una **funci√≥n de activaci√≥n**. Esto es, una funci√≥n que permite el paso de informaci√≥n de acuerdo a la entrada y los pesos, permitiendo el disparo del lo procesado hacia la salida. La funci√≥n de salto se ve como sigue:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4a/Funci%C3%B3n_Cu_H.svg\" width=\"40%\" alt=\"Funci√≥n escal√≥n de Heaviside\">\n",
        "</center>\n",
        "\n",
        "Sin embargo, podemos hacer a una neurona a√∫n m√°s susceptible con respecto a los datos de la misma (entradas, pesos, bias) a√±adiendo una funci√≥n [sigmoide](https://es.wikipedia.org/wiki/Funci%C3%B3n_sigmoide). Esta fue una de las agregaciones de Rosenblatt al momento del desarrollo de su propuesta de perceptr√≥n. La funci√≥n sigmoide se ve como a continuaci√≥n:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/66/Funci%C3%B3n_sigmoide_01.svg\" width=\"40%\" alt=\"Funci√≥n sigmoide\">\n",
        "</center>\n",
        "\n",
        "Esta funci√≥n es suave, y por lo tanto tiene una diferente \"sensibililad\" a los cambios abruptos de valores. Tambi√©n, sus entradas en lugar de solo ser $1$'s o $0$'s, pueden ser valores en todos los n√∫meros reales. La funci√≥n sigmoide es descrita por la siguiente expresi√≥n matem√°tica:\n",
        "\n",
        "$$f(z) = \\dfrac{1}{1+e^{-z}}$$\n",
        "\n",
        "O escrito en t√©rminos de entradas, pesos y bias:\n",
        "\n",
        "$$f(z) = \\dfrac{1}{1+\\exp{\\left\\{-\\left(\\displaystyle\\sum_{j}w_jx_j +b\\right)\\right\\}}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G1MY4HQFsEd"
      },
      "source": [
        "#### **Volviendo al ejemplo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSn8VaEoDtHo"
      },
      "source": [
        "# Modificamos para a√±adir la funci√≥n de activaci√≥n\n",
        "class Perceptron(TLU):\n",
        "    def predict(self, bias):\n",
        "        \"\"\"Function that operates inputs @ weights.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        bias : int\n",
        "            The bias value for operation.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Inner product of data + bias\n",
        "        # TODO: Apply sigmoid function f(z) = 1 / (1 + e^(-z))\n",
        "        z = None\n",
        "        return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogPy6NpfERfJ"
      },
      "source": [
        "bias = int(input(\"¬∑ El nuevo bias ser√°: \"))\n",
        "perceptron = None # TODO Instantiate Perceptron\n",
        "None # TODO Apply decision function with threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRGlbVZsFxdk"
      },
      "source": [
        "> Esta es la neurona que usaremos para los siguientes t√≥picos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvmIk2G9EgOQ"
      },
      "source": [
        "<center>\n",
        "    *********\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnY-np7LE3lS"
      },
      "source": [
        "## **Secci√≥n II**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aprendizaje de neuronas\n",
        "\n",
        "Veamos c√≥mo se puede entrenar una sola neurona para hacer una predicci√≥n.\n",
        "\n",
        "Para este problema construiremos un perceptr√≥n simple, como el propuesto por McCulloch & Pitts, usando la funci√≥n sigmoide.\n",
        "\n",
        "#### **Planteamiento del problema:**\n",
        "\n",
        "Queremos mostrarle a una neurona simple un conjunto de ejemplos para que pueda aprender c√≥mo se comporta una funci√≥n. El conjunto de ejemplos es el siguiente:\n",
        "\n",
        "- `(1, 0)` deber√≠a devolver `1`.\n",
        "- `(0, 1)` debe devolver `1`.\n",
        "- `(0, 0)` deber√≠a devolver `0`.\n",
        "\n",
        "Entonces, si ingresamos a la neurona el valor de `(1, 1)`, deber√≠a poder predecir el n√∫mero `1`.\n",
        "\n",
        "> **Pregunta clave:** Esta funci√≥n corresponde a una compuerta l√≥gica, ¬øpuedes adivinar cu√°l?\n",
        "\n",
        "#### ¬øQue necesitamos hacer?\n",
        "\n",
        "Programar y entrenar una neurona para hacer predicciones.\n",
        "\n",
        "En concreto, vamos a hacer lo siguiente:\n",
        "\n",
        "- Construir la clase y su constructor.\n",
        "- Definir la funci√≥n sigmoide y su derivada\n",
        "- Definir el n√∫mero de √©pocas para el entrenamiento.\n",
        "- Resolver el problema y predecir el valor de la entrada deseada"
      ],
      "metadata": {
        "id": "I7-Ja9DK9cIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class TrainableNeuron():\n",
        "    def __init__(self, n):\n",
        "        \"\"\"Class constructor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n : int\n",
        "            Input size.\n",
        "        \"\"\"\n",
        "\n",
        "        np.random.seed(123)\n",
        "        # TODO. Use np.random.random((n, 1)) to gen values in (-1, 1)\n",
        "        self.synaptic_weights = None\n",
        "        # TODO. Use np.random.random() to gen values in (-1, 1)\n",
        "        self.bias = None\n",
        "\n",
        "    def __sigmoid(self, x):\n",
        "        \"\"\"Sigmoid function.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            Input value to sigmoid function.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Return result of sigmoid function f(z) = 1 / (1 + e^(-z))\n",
        "        return None\n",
        "\n",
        "    def __sigmoid_derivative(self, x):\n",
        "        \"\"\"Derivative of the Sigmoid function.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            Input value to evaluated sigmoid function.\"\"\"\n",
        "\n",
        "        # TODO: Return the derivate of sigmoid function x * (1 - x)\n",
        "        return None\n",
        "\n",
        "    def train(self, training_inputs, training_output, epochs, learning_rate=0.1):\n",
        "        \"\"\"Training function.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        training_inputs : list\n",
        "            List of features for training.\n",
        "        training_outputs : list\n",
        "            List of labels for training.\n",
        "        epochs : int\n",
        "            Number of iterations for training.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        history : list\n",
        "            A list containing the training history.\n",
        "        \"\"\"\n",
        "\n",
        "        # Historial de entrenamiento\n",
        "        history = []\n",
        "\n",
        "        # Transposici√≥n de vector de muestras\n",
        "        real_output = training_output.reshape((len(training_inputs), 1))\n",
        "\n",
        "\n",
        "        for iteration in tqdm(range(epochs)):\n",
        "            # Predicci√≥n de valores\n",
        "            predicted_output = self.predict(training_inputs)\n",
        "\n",
        "            # Error simple\n",
        "            error = real_output - predicted_output\n",
        "\n",
        "            # Error m√°s elaborado (log-loss)\n",
        "            #error = - real_output * np.log(predicted_output) \\\n",
        "            #        - (1 - real_output) * predicted_output\n",
        "            #error /= len(predicted_output)\n",
        "\n",
        "            # Ajuste de pesos\n",
        "            w_adj = learning_rate * \\\n",
        "                np.dot(training_inputs.T, error *\n",
        "                       self.__sigmoid_derivative(predicted_output))\n",
        "            b_adj = learning_rate * \\\n",
        "                np.sum(error *\n",
        "                       self.__sigmoid_derivative(predicted_output))\n",
        "            self.synaptic_weights += w_adj\n",
        "            self.bias += b_adj\n",
        "\n",
        "            history.append(np.linalg.norm(error))\n",
        "\n",
        "        return history\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"Prediction function. Applies input function to inputs tensor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of inputs to apply sigmoid function.\n",
        "        \"\"\"\n",
        "        # TODO: Apply self.__sigmoid to np.dot of (inputs, self.synaptic_weights) + bias\n",
        "        return None"
      ],
      "metadata": {
        "id": "2NKx40hxqmo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generando las muestras\n",
        "\n",
        "Ahora podemos generar una lista de ejemplos basados en la descripci√≥n del problema."
      ],
      "metadata": {
        "id": "Ym_oEzbhxYKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training samples:\n",
        "input_values = []   # TODO. Define the input values as a list of tuples\n",
        "output_values = []  # TODO. Define the desired outputs\n",
        "\n",
        "training_inputs = np.array(input_values)\n",
        "training_output = np.array(output_values).T.reshape((3, 1))"
      ],
      "metadata": {
        "id": "BYW9aYSCxc1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenando la neurona\n",
        "\n",
        "Para hacer el entrenamiento, primero definiremos una neurona. De forma predeterminada, contendr√° pesos aleatorios (ya que a√∫n no se ha entrenado):"
      ],
      "metadata": {
        "id": "DJUYV8H-xf7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = None # TODO Instantiate Trainable Neuron\n",
        "\n",
        "print(\"Pesos iniciales (aleatorios):\")\n",
        "print(neuron.synaptic_weights)\n",
        "print()\n",
        "print(\"Bias inicial (aleatorio):\")\n",
        "print(neuron.bias)"
      ],
      "metadata": {
        "id": "cThkcQGMxrX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO.\n",
        "# Modifiquemos el n√∫mero de √©pocas de entranemiento para ver el\n",
        "# performance de la neurona.\n",
        "epochs = 0\n",
        "\n",
        "# Entrenamos la neurona por tantas √©pocas\n",
        "history = neuron.train(training_inputs, training_output, epochs)\n",
        "\n",
        "print()\n",
        "print()\n",
        "print(\"Pesos despu√©s del entrenamiento:\")\n",
        "print(neuron.synaptic_weights)\n",
        "print()\n",
        "print(\"Bias despu√©s del entrenamiento:\")\n",
        "print(neuron.bias)"
      ],
      "metadata": {
        "id": "WnuCP6eHxtQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos evaluar el entrenamiento de la neurona."
      ],
      "metadata": {
        "id": "7KFucScQncbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "eje_x = np.arange(len(history))\n",
        "\n",
        "fig = px.line(\n",
        "    x=eje_x,\n",
        "    y=history,\n",
        "    title=\"Historia de entrenamiento\",\n",
        "    labels=dict(x=\"√âpocas\", y=\"Error\")\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "8vhWL1nLnZ-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Realizando predicciones"
      ],
      "metadata": {
        "id": "7vPb5a65x0bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos predicciones para verificar el resultado esperado\n",
        "one_one = np.array((1, 1))\n",
        "\n",
        "print('Predicci√≥n para (1, 1): ')\n",
        "neuron.predict(one_one)"
      ],
      "metadata": {
        "id": "YlhaCvTeyeYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Pregunta clave:** ¬øC√≥mo se ven los datos utilizados para entrenamiento? ¬øQu√© suceder√≠a si intent√°ramos utilizar la compuerta XOR?\n"
      ],
      "metadata": {
        "id": "HLX-jyCzL4y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "# Construcci√≥n de una rejilla\n",
        "x = np.linspace(-0.5, 1.5, 201)\n",
        "y = np.linspace(-0.5, 1.5, 201)\n",
        "xy = np.meshgrid(x, y)\n",
        "zz = np.array(list(zip(*(x.flat for x in xy))))\n",
        "\n",
        "# Predicci√≥n en la rejilla de valores\n",
        "surface = neuron.predict(zz).flatten()\n",
        "\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=zz[:, 0],\n",
        "    y=zz[:, 1],\n",
        "    z=surface,\n",
        "    mode=\"markers\",\n",
        "    marker=dict(\n",
        "        size=1,\n",
        "        color=surface,\n",
        "        colorscale=\"Viridis\",\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "# Tight layout\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "eKWk09Q9L8UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IHtR4uPEaCO"
      },
      "source": [
        "<center>\n",
        "    *********\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NE4e3KuEVst"
      },
      "source": [
        "## **Secci√≥n III ‚Äì Tarea(s)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### El dataset a utilizar: Aprobaci√≥n de estudiantes\n",
        "\n",
        "Simularemos datos de 500 estudiantes con estas caracter√≠sticas:\n",
        "\n",
        "- üïê Horas de estudio por semana (distribuidas alrededor de 5h)\n",
        "- üìù Calificaciones previas (media cercana a 7.5)\n",
        "\n",
        "Crearemos un \"√≠ndice de aprobaci√≥n\" combinando ambos factores. Esta ser√° la \"f√≥rmula secreta\" üß™ para etiquetar si aprueban o no. (¬øSer√° que la neurona podr√° descubrirla?)\n",
        "\n",
        "Si ese √≠ndice > 0.7, consideraremos que el estudiante aprueba. üéØ\n",
        "\n",
        "‚Üí As√≠ nacen nuestras etiquetas. ‚úÖ / ‚ùå\n"
      ],
      "metadata": {
        "id": "cDv_Pu8PmnWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la paqueter√≠a de Python que utilizaremos.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Fijaremos una semilla aleatoria para fines de replicabilidad del experimento.\n",
        "np.random.seed(123)\n",
        "\n",
        "# Especificamos el tama√±o de las muestras.\n",
        "n = 500\n",
        "\n",
        "\n",
        "# Crearemos dos variables a partir de una distribuci√≥n normal:\n",
        "#  ‚Üí Horas de estudio ~ N(ùúá=5, ùúé¬≤=2)\n",
        "#  ‚Üí Promedio de calificaciones previas ~ N(ùúá=7.5, ùúé¬≤=1)\n",
        "horas_estudio = np.random.normal(5, 2, n).clip(0, 10)\n",
        "calif_previas = np.random.normal(7.5, 1, n).clip(0, 10)\n",
        "\n",
        "# Con ello, creamos la matriz de entrada (para entrenar la neurona).\n",
        "X = np.column_stack((horas_estudio, calif_previas))\n",
        "\n",
        "# Generamos la etiqueta: √çndice de aprobaci√≥n:\n",
        "indice_aprob = (0.4 * horas_estudio + 0.6 * calif_previas) / 10\n",
        "\n",
        "# Si el √≠ndice de aprobaci√≥n es mayor a 0.7, consieraremos al\n",
        "# estudiante como aprobado.\n",
        "y_true = (indice_aprob > 0.7).astype(int)\n",
        "\n",
        "# Total de estudiantes aprobados en los datos simulados:\n",
        "print(f\"Total de estudiantes aprobados: {sum(y_true)}\")\n",
        "print(f\"Porcentaje de aprobaci√≥n: {sum(y_true)/n*100:.2f}%\")"
      ],
      "metadata": {
        "id": "-4GP3LJUrH9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîç Visualizaci√≥n de los datos\n",
        "\n",
        "Antes del entrenamiento, los datos se ven como a continuaci√≥n.\n",
        "\n",
        "Cada punto es un estudiante, coloreado por si aprob√≥ (üü¢) o no (üî¥).\n",
        "\n",
        "**Podemos observar que hay una cierta separaci√≥n...**\n",
        "Esta separaci√≥n nos ayuda a identificar una regi√≥n en el plano que separa a los estudiantes aprobados de los reprobados.\n",
        "\n",
        "¬øSer√° capaz la neurona de descubrirla por s√≠ sola? ü§î"
      ],
      "metadata": {
        "id": "5wMChnYcrYQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificamos el estilo del gr√°fico.\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "\n",
        "# Creamos una figura.\n",
        "fig = plt.figure(figsize=(7, 6), dpi=300)\n",
        "\n",
        "# Agregamos el gr√°fico de dispersi√≥n de los datos.\n",
        "scatter = plt.scatter(\n",
        "    horas_estudio, calif_previas,\n",
        "    c=y_true, cmap='RdYlGn', alpha=0.6\n",
        ")\n",
        "\n",
        "# Especificamos los l√≠mites de la gr√°fica.\n",
        "x_min, x_max = horas_estudio.min() - 1, horas_estudio.max() + 1\n",
        "y_min, y_max = calif_previas.min() - 1, calif_previas.max() + 1\n",
        "plt.xlim(x_min, x_max)\n",
        "plt.ylim(y_min, y_max)\n",
        "\n",
        "# Agregamos las etiquetas de los ejes y el t√≠tulo del gr√°fico.\n",
        "plt.xlabel(\"Horas de estudio\")\n",
        "plt.ylabel(\"Calificaciones previas\")\n",
        "plt.title(\"Gr√°fico de dispersi√≥n de los datos\")\n",
        "plt.colorbar(scatter, label=\"0 = Reprueba, 1 = Aprueba\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h7ueCQfZrSPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Del grafico anterior podemos observar varios datos interesantes:\n",
        "- Notamos que el m√≠nimo de horas dedicadas al estudio es de 0, sin embargo, podemos observar nadie con esta cantidad de horas de estudio est√° aprobado. Por otro lado, que el m√≠nimo de horas estudiadas hasta que aparece el primer aprobado es de cerca de 4 horas de estudio. Esto puede sugerir que estudiar es un factor importante para aprobar.\n",
        "- Por otro lado, si bien podemos identificar a algunos estudiantes con un √≠ndice de aprobaci√≥n positivo a pesar de tener un promedio de calificaciones bajo, notamos en esas mismas observaciones que dichos estudiantes tienen una cantidad considerable de horas de estudio, sugiriendo que estudiar puede ayudar a tener un √≠ndice de aprobaci√≥n positivo.\n"
      ],
      "metadata": {
        "id": "eFHxZCdRrhbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìâ Entrenamiento\n",
        "\n",
        "Entrenamos la neurona para que aprenda a distinguir qui√©n aprueba y qui√©n no.\n",
        "\n",
        "Para ello usamos descenso de gradiente y entrop√≠a cruzada como funci√≥n de p√©rdida.\n",
        "\n",
        "Resultado: la p√©rdida disminuye con cada √©poca, ¬°se est√° entrenando!\n",
        "\n",
        "**üîΩ Aqu√≠ el gr√°fico de disminuci√≥n del error en su predicci√≥n.**"
      ],
      "metadata": {
        "id": "iHP5z60YrkPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = None #TODO: Create a neuron instance\n",
        "neuron.synaptic_weights, neuron.bias"
      ],
      "metadata": {
        "id": "HzgNNFJ0rtd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 0\n",
        "history = neuron.train(X, y_true, epochs=epochs)"
      ],
      "metadata": {
        "id": "bzrvBL1ar3Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "eje_x = np.arange(len(history))\n",
        "\n",
        "fig = px.line(\n",
        "    x=eje_x,\n",
        "    y=history,\n",
        "    title='Historia de entrenamiento',\n",
        "    labels=dict(x='√âpocas', y='Error')\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "AZG32AwUr-27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ú® Frontera de decisi√≥n aprendida\n",
        "\n",
        "**¬°Y lo logra!**\n",
        "\n",
        "Despu√©s de entrenarse, la neurona aprende una frontera de decisi√≥n que separa ambos grupos.\n",
        "\n",
        "Esa l√≠nea (aprendida por los pesos w y el sesgo b) es lo que usa para decidir si alguien aprueba o no.\n",
        "\n",
        "üß† En general, as√≠ aprende una red neuronal artificial, ajustando los par√°metros asociados a cada neurona que conforma la red."
      ],
      "metadata": {
        "id": "J4hmAfvKsxHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos los par√°metros\n",
        "w = neuron.synaptic_weights\n",
        "b = neuron.bias\n",
        "\n",
        "# Creamos una figura.\n",
        "fig = plt.figure(figsize=(7, 6), dpi=300)\n",
        "\n",
        "# Agregamos el gr√°fico de dispersi√≥n de los datos.\n",
        "scatter = plt.scatter(\n",
        "    horas_estudio, calif_previas,\n",
        "    c=y_true, cmap='RdYlGn', alpha=0.6\n",
        ")\n",
        "\n",
        "# Especificamos los l√≠mites de la gr√°fica.\n",
        "x_min, x_max = horas_estudio.min() - 1, horas_estudio.max() + 1\n",
        "y_min, y_max = calif_previas.min() - 1, calif_previas.max() + 1\n",
        "plt.xlim(x_min, x_max)\n",
        "plt.ylim(y_min, y_max)\n",
        "\n",
        "# Agregamos las etiquetas de los ejes y el t√≠tulo del gr√°fico.\n",
        "plt.xlabel(\"Horas de estudio\")\n",
        "plt.ylabel(\"Calificaciones previas\")\n",
        "plt.title(\"Clasificaci√≥n de estudiantes: ¬øAprueba o no?\")\n",
        "plt.colorbar(scatter, label=\"0 = Reprueba, 1 = Aprueba\")\n",
        "\n",
        "# Frontera de decisi√≥n: w1*x + w2*y + b = 0 => y = (-w1*x - b)/w2\n",
        "x_vals = np.linspace(0, 10, 100)\n",
        "y_boundary = -(w[0] * x_vals + b) / w[1]\n",
        "plt.plot(x_vals, y_boundary, 'k--', label=\"Frontera de decisi√≥n\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T5LHvRlksyXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z7JrTygMDSx"
      },
      "source": [
        "### El dataset a utilizar: Naranjas vs. Manzanas\n",
        "\n",
        "El dataset ha sido una adaptaci√≥n de datos encontrados en [Kaggle](https://www.kaggle.com/datasets/theblackmamba31/apple-orange). Dicho dataset est√° compuesto por conjuntos de im√°genes de naranjas y manzanas que ser√°n un utilizados para entrenar una neurona artificial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cargar los datos, primero los descargaremos de un repositorio donde previamente los prepar√© para ustedes.\n",
        "\n",
        "Puedes explorar directamente los archivos fuente del [repositorio en GitHub ‚Äì `apple-orange-dataset`](https://github.com/RodolfoFerro/apple-orange-dataset).\n",
        "\n",
        "Puedes tambi√©n explorar el [script](https://github.com/RodolfoFerro/apple-orange-dataset/blob/main/script.py) que he utilizado para la preparaci√≥n de los mismos."
      ],
      "metadata": {
        "id": "UVg0AU2-Fqzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/RodolfoFerro/apple-orange-dataset/main/training_data.csv\n",
        "!wget https://raw.githubusercontent.com/RodolfoFerro/apple-orange-dataset/main/testing_data.csv"
      ],
      "metadata": {
        "id": "1S81FXVEFzQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxfNdPU3NQge"
      },
      "source": [
        "### Preparaci√≥n de los datos\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "training_df = pd.read_csv('training_data.csv')\n",
        "testing_df = pd.read_csv('testing_data.csv')\n",
        "\n",
        "training_df"
      ],
      "metadata": {
        "id": "4fh3DURvLBvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_df['class_str'] = training_df['class'].astype('str')\n",
        "training_df['hover'] = [text.split('/')[-1] for text in training_df['filename']]\n",
        "\n",
        "testing_df['class_str'] = testing_df['class'].astype('str')\n",
        "testing_df['hover'] = [text.split('/')[-1] for text in testing_df['filename']]\n",
        "\n",
        "training_df"
      ],
      "metadata": {
        "id": "8IWxRHjQ4GS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploraci√≥n de los datos"
      ],
      "metadata": {
        "id": "h7SGMNlqx8Dx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos verificar si el conjunto de datos est√° balanceado:"
      ],
      "metadata": {
        "id": "wRHZdY0B4NNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_df.groupby('class').count()"
      ],
      "metadata": {
        "id": "dOvDsf0V3i7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos explorar c√≥mo se ven los datos en un gr√°fico 3D:"
      ],
      "metadata": {
        "id": "5MVOWcHT4Qiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    training_df,\n",
        "    x='r', y='g', z='b',\n",
        "    color='class_str',\n",
        "    symbol='class_str',\n",
        "    color_discrete_sequence=['#be0900', '#ffb447'],\n",
        "    opacity=0.5,\n",
        "    hover_data=['hover']\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "RXINRt1ox_-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes explorar las im√°genes y sus valores de color utilizando el color picker que ofrece Google: https://g.co/kgs/uarXyu\n",
        "\n",
        "> **Pregunta clave:** ¬øLos datos son linealmente separables? Con lo que hemos explorado hasta ahora, ¬øbasta una neurona para resolver el problema planteado?"
      ],
      "metadata": {
        "id": "L8aw6ijc3QZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creaci√≥n de una neurona artificial\n"
      ],
      "metadata": {
        "id": "npjrVs7jUBC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = None #TODO: Create a neuron instance\n",
        "neuron.synaptic_weights"
      ],
      "metadata": {
        "id": "eHmZ4nnccToB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del modelo\n",
        "\n",
        "Para entrenar el modelo, simplemente utilizamos el m√©todo `.train()` del modelo.\n",
        "\n",
        "Antes de entrenar los datos, procedemos a escalarlos a valores en [0, 1]."
      ],
      "metadata": {
        "id": "B4DmYPVAUJ2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_inputs = training_df[['r', 'g', 'b']].values / 255.\n",
        "training_output = training_df['class'].values\n",
        "\n",
        "training_inputs, training_output"
      ],
      "metadata": {
        "id": "_0o5NZsB7ORw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = None #TODO: Train a neuron"
      ],
      "metadata": {
        "id": "KX3X_t7B73NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluaci√≥n y predicci√≥n\n",
        "\n",
        "Podemos evaluar el entrenamiento de la neurona."
      ],
      "metadata": {
        "id": "_2oyTh_jMAIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "eje_x = np.arange(len(history))\n",
        "\n",
        "fig = px.line(\n",
        "    x=eje_x,\n",
        "    y=history,\n",
        "    title='Historia de entrenamiento',\n",
        "    labels=dict(x='√âpocas', y='Error')\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "buRgAf7xLvln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **Pregunta clave:** ¬øQu√© sucede con la historia de entrenamiento?\n",
        "\n",
        "> **Pro-tip:** Exploremos con una nueva funci√≥n de p√©rdida, qu√© tal la utilizada usualemente en una regresi√≥n log√≠stica: https://developers.google.com/machine-learning/crash-course/logistic-regression/model-training"
      ],
      "metadata": {
        "id": "KMX5Gjzu92e1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para predecir un color de ejemplo:"
      ],
      "metadata": {
        "id": "ZsC5ELq7Ad-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparamos los datos\n",
        "sample_index = 0\n",
        "\n",
        "input_sample = testing_df[['r', 'g', 'b']].iloc[sample_index].values\n",
        "# input_sample = np.array([])\n",
        "print('Color real:', input_sample)\n",
        "\n",
        "input_sample = input_sample / 255.\n",
        "print('Color transformado:', input_sample)\n",
        "\n",
        "real_class = testing_df[['class']].iloc[sample_index].values\n",
        "print('Clase real:', real_class)"
      ],
      "metadata": {
        "id": "kLqvq2cnUfdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.predict(input_sample).tolist()"
      ],
      "metadata": {
        "id": "l8mB_4-T6l7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar esta tarea, vamos a utilizar funciones de scikit-learn para la que nos permitir√°n realizar la evaluaci√≥n de resultados en el conjunto de pruebas. (Utilizar [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score))"
      ],
      "metadata": {
        "id": "8ubrtbZdoJ-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    *********\n",
        "</center>"
      ],
      "metadata": {
        "id": "hMCddqlrYosR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    testing_df,\n",
        "    x='r', y='g', z='b',\n",
        "    color='class_str',\n",
        "    symbol='class_str',\n",
        "    color_discrete_sequence=['#be0900', '#ffb447'],\n",
        "    opacity=0.5,\n",
        "    hover_data=['hover']\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "20x0UwqUAtdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(testing_df, threshold=0.5):\n",
        "    testing_inputs = testing_df[['r', 'g', 'b']].values / 255.\n",
        "    testing_output = testing_df['class'].values\n",
        "\n",
        "    predictions = []\n",
        "    for test_input in testing_inputs:\n",
        "        if neuron.predict(test_input)[0] <= threshold:\n",
        "            prediction = 0\n",
        "        else:\n",
        "            prediction = 1\n",
        "        predictions.append(prediction)\n",
        "    predictions = np.array(predictions)\n",
        "\n",
        "    return testing_output, predictions"
      ],
      "metadata": {
        "id": "tccP9w_EBGvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "testing_output, predictions = get_predictions(testing_df, threshold=0.5)\n",
        "result = accuracy_score(testing_output, predictions)\n",
        "print(f'Accuracy: {result * 100:.6}%')"
      ],
      "metadata": {
        "id": "JZvNFNY4B-Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Pregunta clave:** ¬øQu√© sucede si cambiamos el _threshold_ a 0.7? A veces conviene explorar el valor de umbral que seleccionamos y no siempre dar por hecho que 0.5 va a funcionar todas las veces. <br><br>\n",
        "> Lee m√°s aqu√≠: https://ploomber.io/blog/threshold/"
      ],
      "metadata": {
        "id": "fYFSRK0P_c1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Para resolver la tarea, el reto es:** Mejor accuracy obtenido en la clase.\n",
        "\n",
        "**Puedes explorar:**\n",
        "- Utilizar 1 a 3 variables (de las dadas).\n",
        "- Investigar e implementar una nueva funci√≥n para estimar el error.\n",
        "- Realizar transformaciones en los datos.\n",
        "- Entrenar por m√°s √©pocas.\n",
        "- Mover el umbral para definir la clase.\n",
        "- Explorar otras funciones de activaci√≥n.\n",
        "- Generar tu nuevo dataset de datos a partir de las im√°genes originales."
      ],
      "metadata": {
        "id": "QKp_PZ_NDqbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "\n",
        "> Contenido creado por **Rodolfo Ferro**, 2023-2025. <br>\n",
        "> Puedes contactarme a trav√©s de Insta ([@rodo_ferro](https://www.instagram.com/rodo_ferro/)) o X ([@rodo_ferro](https://twitter.com/rodo_ferro))."
      ],
      "metadata": {
        "id": "hSdbQU3e6-Ky"
      }
    }
  ]
}