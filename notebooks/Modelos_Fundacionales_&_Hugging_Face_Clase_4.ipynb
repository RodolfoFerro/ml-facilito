{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b3fc626bdd164cab921c17ff9b8444df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_367de7a841f64203ae28ab11c958617c",
              "IPY_MODEL_902205e2680846559b4a36c0c8c2fa19",
              "IPY_MODEL_3f23ea40a991451eb2770681f16eff7f"
            ],
            "layout": "IPY_MODEL_098043635bad4ae084cf8e0f23894d65"
          }
        },
        "367de7a841f64203ae28ab11c958617c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e1f54c2f41241949eca845ecfe8d43d",
            "placeholder": "​",
            "style": "IPY_MODEL_9e1328f6897545f28f0cbc0c159f44f4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "902205e2680846559b4a36c0c8c2fa19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cdcfd6a11b14a7587aba97f8944d514",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_239e8cf657d443569a3552f2c2db0407",
            "value": 48
          }
        },
        "3f23ea40a991451eb2770681f16eff7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56eb94e276594de188e09e97ef946454",
            "placeholder": "​",
            "style": "IPY_MODEL_6a9f5e990c814bdf80137ceb28d2bc78",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.05kB/s]"
          }
        },
        "098043635bad4ae084cf8e0f23894d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e1f54c2f41241949eca845ecfe8d43d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e1328f6897545f28f0cbc0c159f44f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cdcfd6a11b14a7587aba97f8944d514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "239e8cf657d443569a3552f2c2db0407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56eb94e276594de188e09e97ef946454": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9f5e990c814bdf80137ceb28d2bc78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd6f315010a9451793d5d350c173cd54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c63c6874f0149c8b72e9f6170fa34f4",
              "IPY_MODEL_3a679505d4be4d3588dde75c0248394d",
              "IPY_MODEL_2f4ccd66a080449b93aec85b5f256c7a"
            ],
            "layout": "IPY_MODEL_ec1332ac59f54dd7b9bf699baba9f914"
          }
        },
        "2c63c6874f0149c8b72e9f6170fa34f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb9b6372f64d4dc0a296d7ae0ac94c47",
            "placeholder": "​",
            "style": "IPY_MODEL_ce6492d186164330a79af8bf779e42a7",
            "value": "config.json: 100%"
          }
        },
        "3a679505d4be4d3588dde75c0248394d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_927af916c17c4ce0a17d9ba147a6841a",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7c4623bea164bb688c24b4fb49dc148",
            "value": 629
          }
        },
        "2f4ccd66a080449b93aec85b5f256c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a33524a0f6cd4339a47377ed0d6c080f",
            "placeholder": "​",
            "style": "IPY_MODEL_d39f03963a504496aa3bb1387ef5e258",
            "value": " 629/629 [00:00&lt;00:00, 18.1kB/s]"
          }
        },
        "ec1332ac59f54dd7b9bf699baba9f914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9b6372f64d4dc0a296d7ae0ac94c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce6492d186164330a79af8bf779e42a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "927af916c17c4ce0a17d9ba147a6841a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c4623bea164bb688c24b4fb49dc148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a33524a0f6cd4339a47377ed0d6c080f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39f03963a504496aa3bb1387ef5e258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99c87ebd03a746519c5c297236c3bf02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_830050befd834e7a99ccb0f9f95b79cb",
              "IPY_MODEL_cb6f962c5bde477c8ee2c3a66ef7c7dc",
              "IPY_MODEL_fd406763ad8648fab7860fe2b1d04258"
            ],
            "layout": "IPY_MODEL_200a725040f14bc789eac0f9a62654f7"
          }
        },
        "830050befd834e7a99ccb0f9f95b79cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1a2e39b755c4a3dbab973c485abebb0",
            "placeholder": "​",
            "style": "IPY_MODEL_b09b5ab0fcfe42588cb81824723e440a",
            "value": "vocab.txt: 100%"
          }
        },
        "cb6f962c5bde477c8ee2c3a66ef7c7dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba9d95e0f4b845df8906153d28edbd9b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f3a52deedc5459aa6ff89746ded0ffe",
            "value": 231508
          }
        },
        "fd406763ad8648fab7860fe2b1d04258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0078dc3222ca422599eed97de5175da2",
            "placeholder": "​",
            "style": "IPY_MODEL_5ad11ca9417b47f5a5654e035abf1e58",
            "value": " 232k/232k [00:00&lt;00:00, 7.63MB/s]"
          }
        },
        "200a725040f14bc789eac0f9a62654f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1a2e39b755c4a3dbab973c485abebb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09b5ab0fcfe42588cb81824723e440a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba9d95e0f4b845df8906153d28edbd9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f3a52deedc5459aa6ff89746ded0ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0078dc3222ca422599eed97de5175da2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad11ca9417b47f5a5654e035abf1e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/ml-facilito/blob/main/notebooks/Modelos_Fundacionales_%26_Hugging_Face_Clase_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6jO_1gISKxk"
      },
      "source": [
        "# Modelos Fundacionales & Hugging Face - Clase 4  🧠\n",
        "\n",
        "> **Descripción:** Cuaderno de contenidos (IV) sobre Modelos Fundacionales & Hugging Face para el Bootcamp de Machine Learning con Código Facilito, 2023. <br>\n",
        "> **Autor:** [Rodolfo Ferro](https://github.com/RodolfoFerro) <br>\n",
        "> **Contacto:** [X](https://twitter.com/rodo_ferro) / [Instagram](https://www.instagram.com/rodo_ferro/)\n",
        "\n",
        "\n",
        "## Contenido\n",
        "\n",
        "### Modelos fundacionales\n",
        "\n",
        "* ¿Qué son los modelos fundacionales?\n",
        "* Características de los modelos fundacionales\n",
        "* ¿Por qué es importante el modelado fundacional?\n",
        "* ¿Cómo funcionan los modelos fundacionales?\n",
        "* ¿Qué pueden hacer los modelos fundacionales?\n",
        "* Ejemplos de modelos fundacionales\n",
        "\n",
        "\n",
        "### Hugging Face - *Transformers*\n",
        "\n",
        "* a\n",
        "\n",
        "\n",
        "### Hugging Face – *Fine Tuning* de modelos\n",
        "\n",
        "* a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVG2PnSEtQN"
      },
      "source": [
        "## **Modelos fundacionales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPk1Rkc4FZ5g"
      },
      "source": [
        "### **¿Qué son los modelos fundacionales?**\n",
        "\n",
        "Los **modelos fundacionales**, o FMs, son **redes neuronales de aprendizaje profundo** que han transformado el enfoque de los científicos en el machine learning.\n",
        "\n",
        "*Estos modelos se entrenan con grandes conjuntos.*\n",
        "\n",
        "> **IDEA:** En lugar de desarrollar IA desde cero, las y los científicos de datos utilizan un modelo fundacional como punto de partida para desarrollar modelos de ML que impulsen aplicaciones nuevas de manera rápida y rentable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Características de los modelos fundacionales**\n",
        "\n",
        "La **característica distintiva** de los modelos fundacionales es su **capacidad de adaptarse**. Estos modelos pueden realizar diversas tareas con alta precisión, como procesamiento de lenguaje natural, respuesta a preguntas y clasificación robusta de imágenes.\n",
        "\n",
        "El tamaño y la versatilidad de los modelos fundamentales los distinguen de los modelos convencionales de aprendizaje automático, los cuales típicamente se especializan en tareas particulares, como examinar texto para evaluar opiniones, categorizar imágenes y prever patrones.\n"
      ],
      "metadata": {
        "id": "AN4GxfmiCnuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **¿Por qué es importante el modelado fundacional?**\n",
        "\n",
        "El modelado fundacional tiene el potencial de **revolucionar el ciclo de vida del machine learning**.\n",
        "\n",
        "Aunque desarrollarlos desde cero es costoso, utilizar modelos pre-entrenados resulta más rápido y económico a largo plazo, impulsando la automatización de diversas aplicaciones.\n",
        "\n",
        "Una aplicación posible implica la automatización de diversas tareas y procesos, especialmente aquellas que demandan habilidades de razonamiento. Algunos ejemplos de áreas donde los FMs podrían utilizarse:\n",
        "\n",
        "* Asistencia al cliente\n",
        "* Traducción de idiomas\n",
        "* Generación de contenido\n",
        "* Redacción de textos publicitarios\n",
        "* Clasificación de imágenes\n",
        "* Creación y edición de imágenes de alta resolución\n",
        "* Extracción de documentos\n",
        "* Sector de la salud\n",
        "\n"
      ],
      "metadata": {
        "id": "OcSLY84GC2ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **¿Cómo funcionan los modelos fundacionales?**\n",
        "\n",
        "Los modelos fundacionales son una forma de **IA generativa**, operan mediante complejas redes neuronales, como las generativas antagónicas/adversariales (GANs), los transformadores (Transformers) y los autoencoders variacionales.\n",
        "\n",
        "> → Ellos generan resultados a partir de una o más entradas (indicaciones) en forma de instrucciones en lenguaje humano.\n"
      ],
      "metadata": {
        "id": "mCbTCwZYDJRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **¿Qué pueden hacer los modelos fundacionales?**\n",
        "\n",
        "A pesar de ser pre-entrenados, los modelos fundacionales pueden continuar aprendiendo de nuevas entradas, realizando tareas como:\n",
        "\n",
        "* Procesamiento del lenguaje natural\n",
        "* Comprensión visual\n",
        "* Generación de código\n",
        "* Voz a texto\n",
        "* Participación centrada en las personas\n"
      ],
      "metadata": {
        "id": "oogP9WMLDQ2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ejemplos de modelos fundacionales**\n",
        "\n",
        "La oferta de modelos fundacionales ha experimentado un rápido crecimiento en tamaño y cantidad en el mercado. Algunos ejemplos notables incluyen:\n",
        "\n",
        "* BERT\n",
        "* GPTs\n",
        "* Stable Diffusion\n",
        "* BLOOM\n",
        "* Gemini…\n",
        "* …y la plataforma Hugging Face.\n"
      ],
      "metadata": {
        "id": "MK354PrQDXpG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlQl_jAunKvb"
      },
      "source": [
        "## **Hugging Face - Transformers**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hugging Face**\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\" width=\"30%\">\n",
        "</center>\n",
        "\n",
        "\n",
        "[Hugging Face](https://huggingface.co/) es una plataforma que ofrece herramientas open-source para la creación e implementación de modelos de ML. Funciona como un punto de encuentro comunitario donde las y los desarrolladores tienen la posibilidad de intercambiar y explorar modelos y conjuntos de datos.\n",
        "\n",
        "**La plataforma ofrece acceso público a casi 200,000 modelos y 30,000 conjuntos de datos.**\n",
        "\n",
        "> La membresía individual es de acceso gratuito, mientras que las\n",
        "suscripciones de pago brindan niveles de acceso más avanzados.\n"
      ],
      "metadata": {
        "id": "fp687hVHnOxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **¿Qué es NLP?**\n",
        "\n",
        "El **Procesamiento del Lenguaje Natural** (PLN/NLP) es un campo de la lingüística y el aprendizaje automático que se centra en comprender todo lo relacionado con el lenguaje humano. Su objetivo no es solo entender palabras individualmente, sino comprender el contexto en el que se utilizan.\n",
        "\n",
        "La siguiente es una lista de tareas comunes de procesamiento del lenguaje natural (NLP), con algunos ejemplos de cada una:\n",
        "\n",
        "* **Clasificación de oraciones completas:** Obtener el sentimiento de una reseña, detectar si un correo electrónico es spam, determinar si una oración es gramaticalmente correcta o si dos oraciones están lógicamente relacionadas o no.\n",
        "* **Clasificación de cada palabra en una oración:** Identificar los componentes gramaticales de una oración (sustantivo, verbo, adjetivo) o las entidades nombradas (persona, ubicación, organización).\n",
        "* **Generación de contenido de texto:** Completar un estímulo con texto generado automáticamente, llenar los espacios en blanco en un texto con palabras enmascaradas.\n",
        "* **Extracción de una respuesta de un texto:** Dada una pregunta y un contexto, extraer la respuesta a la pregunta basándose en la información proporcionada en el contexto.\n",
        "Generación de una nueva oración a partir de un texto de entrada: Traducir un texto a otro idioma, resumir un texto.\n",
        "\n",
        "#### **¿Por qué es difícil?**\n",
        "\n",
        "Las computadoras no manejan ni procesan la información de la misma manera que lo hacemos los humanos.\n",
        "\n",
        "Para los modelos de ML, estas tareas son complicadas. Es necesario procesar el texto de manera que permita al modelo aprender de él.\n",
        "\n",
        "Dada la complejidad del lenguaje, es crucial reflexionar sobre cómo llevar a cabo este procesamiento. Se ha llevado a cabo mucha investigación sobre cómo representar el texto."
      ],
      "metadata": {
        "id": "OHcha8EDD8vp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Transformers***\n",
        "\n",
        "Los modelos **Transformer** se emplean para abordar diversas tareas de procesamiento del lenguaje natural.\n",
        "\n",
        "Algunas empresas y organizaciones aprovechan Hugging Face y los modelos *Transformer*, devolviendo también a la comunidad al compartier sus propios modelos.\n",
        "\n",
        "La biblioteca [🤗 Transformers](https://github.com/huggingface/transformers) brinda la funcionalidad necesaria para crear y utilizar estos modelos compartidos.\n",
        "\n",
        "Además, el [Model Hub](https://huggingface.co/models) alberga miles de modelos preentrenados que están disponibles para descargar y utilizar por cualquier persona."
      ],
      "metadata": {
        "id": "jIjoWdYOEK4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para comenzar a usar transformers, la biblioteca Transformers cuenta con el elemento más básico, que es la función `pipeline()`.\n",
        "\n",
        "Esta función conecta un modelo con sus pasos de preprocesamiento y postprocesamiento necesarios, lo que nos permite ingresar directamente cualquier texto y obtener una respuesta comprensible."
      ],
      "metadata": {
        "id": "buDR65LWHLlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"¡Me encanta el bootcamp de ML de Código Facilito!\")"
      ],
      "metadata": {
        "id": "7TmaXov1G-hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier([\n",
        "    \"Feliz navidad para todos ustedes, jingle bells, jingle bells, jingle...\",\n",
        "    \"Hoy no me gusta cómo está el clima.\"\n",
        "])"
      ],
      "metadata": {
        "id": "sEQWmPm7Hohj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De manera predeterminada, este `pipeline` selecciona un modelo pre-entrenado específico que ha sido ajustado para analizar sentimientos. El modelo se descarga y almacena en caché al crear el objeto clasificador.\n",
        "\n",
        "> **Nota:** Si vovlemos a ejecutar el comando, se utilizará el modelo almacenado en caché, evitando la necesidad de volver a descargarlo.\n",
        "\n",
        "Cuando ingresamos un texto en este pipeline, se llevan a cabo tres pasos esenciales:\n",
        "\n",
        "1. El texto se transforma previamente a un formato que el modelo pueda comprender.\n",
        "2. Las entradas preprocesadas se suministran al modelo.\n",
        "3. Las predicciones del modelo se procesan posteriormente para que tengan sentido.\n",
        "\n",
        "Algunos de los pipelines que están disponibles en la actualidad incluyen:\n",
        "\n",
        "* `feature-extraction` (obtención de la representación vectorial de un texto)\n",
        "* `question-answering`\n",
        "* `sentiment-analysis` (análisis de sentimientos)\n",
        "* `summarization` (resumen)\n",
        "* `text-generation` (generación de texto)\n",
        "* `translation` (traducción)\n",
        "* `zero-shot-classification` (clasificación sin etiquetas previas)"
      ],
      "metadata": {
        "id": "Mfza1FInIFHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uso de Transormers**"
      ],
      "metadata": {
        "id": "DuiTEiokI4th"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Generación de texto**"
      ],
      "metadata": {
        "id": "tBnZfa-tJlM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")"
      ],
      "metadata": {
        "id": "41XWHMRaIxHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\"En este bootcamp sobre Machine Learning de Código Facilito aprenderás\")"
      ],
      "metadata": {
        "id": "sRqbF7faJO5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\"In this bootcamp about ML, you'll learn\")"
      ],
      "metadata": {
        "id": "v2cfDRauJRvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos utilizar algún modelo específico, simplemente yendo al [Model Hub](https://huggingface.co/models) y dando click en el tag correspondiente para desplegar modelos asociados a la tarea."
      ],
      "metadata": {
        "id": "1sPKuD8yJrAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")"
      ],
      "metadata": {
        "id": "3zripUL5JthC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\n",
        "    \"In this bootcamp about Machine Learning, you'll learn\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "id": "8Hfl1J2_JyaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Resumen de contenido**"
      ],
      "metadata": {
        "id": "-QJaika1JpZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    La característica distintiva de los modelos fundacionales es su\n",
        "    capacidad de adaptarse. Estos modelos pueden realizar diversas\n",
        "    tareas con alta precisión, como procesamiento de lenguaje natural,\n",
        "    respuesta a preguntas y clasificación robusta de imágenes.\n",
        "\n",
        "    El tamaño y la versatilidad de los modelos fundamentales los\n",
        "    distinguen de los modelos convencionales de aprendizaje automático,\n",
        "    los cuales típicamente se especializan en tareas particulares, como\n",
        "    examinar texto para evaluar opiniones, categorizar imágenes y prever\n",
        "    patrones.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "E_em1LP6MHYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Respuestas a preguntas**"
      ],
      "metadata": {
        "id": "uTwW4Y5VMude"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"¿Cómo me llamo?\",\n",
        "    context=\"Me llamo Rodo. Nací en Guanajuato, México.\",\n",
        ")"
      ],
      "metadata": {
        "id": "9b5ZcMe4Mw-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer(\n",
        "    question=\"Where am I from?\",\n",
        "    context=\"My name is Rodo. I was born in Guanajuato, México.\",\n",
        ")"
      ],
      "metadata": {
        "id": "DpSuwf1ENSiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Otras tareas**\n",
        "\n",
        "Puedes consultar otras tareas de ejemplo en esta [referencia](https://huggingface.co/learn/nlp-course/chapter1/3)."
      ],
      "metadata": {
        "id": "gLty2zBSOFgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **¿Cómo funcionan?**\n",
        "\n",
        "Podríamos decir que en general los Transformers se pueden agrupar en tres categorías:\n",
        "\n",
        "* Estilo GPT (también llamados modelos auto-regresivos Transformer)\n",
        "* Estilo BERT (también llamados modelos auto-codificadores Transformer)\n",
        "* Estilo BART/T5 (también llamados modelos Transformer de secuencia a secuencia)\n",
        "\n",
        "Todos los modelos Transformer mencionados anteriormente (GPT, BERT, BART, T5, etc.) han sido entrenados como modelos de lenguaje. Esto significa que han sido entrenados en grandes cantidades de texto sin procesar de manera auto supervisada.\n",
        "\n",
        "> El aprendizaje auto supervisado es un tipo de entrenamiento en el que el objetivo se calcula automáticamente a partir de las entradas del modelo. ¡Esto significa que no se necesita la intervención humana para etiquetar los datos!\n",
        "\n",
        "Este tipo de modelos desarrollan una comprensión estadística del lenguaje en el que ha sido entrenado, pero no es muy útil para tareas prácticas específicas. Debido a esto, el modelo preentrenado general pasa por un proceso de transfer learning. Durante este proceso, el modelo se ajusta finamente de manera supervisada, es decir, utilizando etiquetas anotadas por humanos, en una tarea específica."
      ],
      "metadata": {
        "id": "hCXtbQ6-b8Zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un ejemplo de tarea es predecir la siguiente palabra en una oración después de haber leído las `n` palabras anteriores. Esto se llama modelado de lenguaje causal porque la salida depende de las entradas pasadas y presentes, pero no de las futuras.\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/causal_modeling.svg\" width=\"80%\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "BxM5lC6jckVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Arquitectura general**\n",
        "\n",
        "El modelo está principalmente compuesto por dos bloques:\n",
        "\n",
        "* **Encoder:** El codificador recibe una entrada y construye una representación de ella (sus características). Esto significa que el modelo está optimizado para adquirir comprensión a partir de la entrada.\n",
        "\n",
        "* **Decoder:** El decodificador utiliza la representación del codificador (características) junto con otras entradas para generar una secuencia objetivo. Esto significa que el modelo está optimizado para generar salidas.\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_blocks.svg\" width=\"60%\">\n",
        "</center>\n",
        "\n",
        "Cada una de estas partes puede utilizarse de forma independiente según la tarea:\n",
        "\n",
        "* **Modelos sólo de codificación:** Útiles para tareas que requieren comprensión de la entrada, como la clasificación de oraciones y el reconocimiento de entidades nombradas.\n",
        "* **Modelos sólo de decodificación:** Apropiados para tareas generativas como la generación de texto.\n",
        "* **Modelos de codificación-decodificación o modelos de secuencia a secuencia:** Eficientes para tareas generativas que requieren una entrada, como la traducción o la síntesis."
      ],
      "metadata": {
        "id": "ijExO_ZkcyvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Capas de atención**\n",
        "\n",
        "Una característica clave de los modelos Transformer es que están construidos con capas especiales llamadas **capas de atención**. De hecho, el título del artículo que introduce la arquitectura Transformer es [\"Attention Is All You Need\"](https://arxiv.org/abs/1706.03762) (\"La Atención es Todo lo que Necesitas\"). Esta capa indicará al modelo que preste atención específica a ciertas palabras en la oración que le pasamos (y más o menos ignore las demás) al tratar con la representación de cada palabra.\n",
        "\n",
        "> Para contextualizar esto, considera la tarea de traducir texto de inglés a francés. Dada la entrada \"You like this course\" (\"Te gusta este curso\"), un modelo de traducción también necesitará prestar atención a la palabra adyacente \"You\" para obtener la traducción adecuada de la palabra \"like\", porque en francés el verbo \"like\" se conjuga de manera diferente según el sujeto. El resto de la oración, sin embargo, no es útil para la traducción de esa palabra. De manera similar, al traducir \"this\" (\"esto\" o \"esta\"), el modelo también deberá prestar atención a la palabra \"course\" (\"curso\"), porque \"this\" se traduce de manera diferente según si el sustantivo asociado es masculino o femenino. Nuevamente, las otras palabras en la oración no importarán para la traducción de \"this\". Con oraciones más complejas (y reglas gramaticales más complejas), el modelo necesitaría prestar especial atención a palabras que puedan aparecer más lejos en la oración para traducir correctamente cada palabra.\n",
        "\n",
        "El mismo concepto se aplica a cualquier tarea asociada con el lenguaje natural: una palabra por sí sola tiene un significado, pero ese significado se ve profundamente afectado por el contexto, que puede ser cualquier otra palabra (o palabras) antes o después de la palabra que se está estudiando."
      ],
      "metadata": {
        "id": "ft_PVZNDdizB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **La arquitectura original**\n",
        "\n",
        "* La arquitectura Transformer fue diseñada originalmente para la traducción. Durante el entrenamiento, el codificador recibe entradas (oraciones) en un cierto idioma, mientras que el decodificador recibe las mismas oraciones en el idioma objetivo deseado.\n",
        "* En el codificador, las capas de atención pueden usar todas las palabras en una oración (ya que, como acabamos de ver, la traducción de una palabra dada puede depender de lo que haya después y antes en la oración).\n",
        "* Sin embargo, el decodificador trabaja de manera secuencial y solo puede prestar atención a las palabras en la oración que ya ha traducido (es decir, solo las palabras antes de la palabra que se está generando en ese momento).\n",
        "\n",
        "Para acelerar las cosas durante el entrenamiento (cuando el modelo tiene acceso a las oraciones objetivo), se le proporciona al decodificador todo el objetivo, pero no se le permite usar palabras futuras. Por ejemplo, al intentar predecir la cuarta palabra, la capa de atención solo tendrá acceso a las palabras en las posiciones 1 a 3.\n",
        "\n",
        "La arquitectura original de Transformer se veía así, con el codificador a la izquierda y el decodificador a la derecha:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers.svg\" width=\"90%\">\n",
        "</center>\n",
        "\n",
        "Observa que la primera capa de atención en un bloque de decodificador presta atención a todas las entradas (pasadas) al decodificador, pero la segunda capa de atención utiliza la salida del codificador. Por lo tanto, puede acceder a toda la oración de entrada para predecir mejor la palabra actual. Esto es muy útil, ya que diferentes idiomas pueden tener reglas gramaticales que colocan las palabras en diferentes órdenes, o algún contexto proporcionado más tarde en la oración puede ser útil para determinar la mejor traducción de una palabra dada.\n",
        "\n",
        "La máscara de atención también se puede utilizar en el codificador/decodificador para evitar que el modelo preste atención a algunas palabras especiales, como la palabra de relleno especial utilizada para igualar la longitud de todas las entradas al agrupar oraciones."
      ],
      "metadata": {
        "id": "EnqWmQ0leGp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Entonces...**\n",
        "\n",
        "Estos elementos te resumen un poco el funcionamiento en alto nivel sobre este tipo de modelos:\n",
        "\n",
        "- Encoding posicional\n",
        "- Atención\n",
        "    - Atención propia (ahora con contexto sobre las palabras alrededor de la observada)"
      ],
      "metadata": {
        "id": "3r-2PGHLfbRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Te recomiendo mucho ver estos videos:\n",
        "\n",
        "\n",
        "*   [¿Qué es un TRANSFORMER? La Red Neuronal que lo cambió TODO!](https://www.youtube.com/watch?v=aL-EmKuB078)\n",
        "*   [Transformers, explained: Understand the model behind GPT, BERT, and T5](https://www.youtube.com/watch?v=SZorAJ4I-sA)\n",
        "* [Illustrated Guide to Transformers Neural Network: A step by step explanation](https://www.youtube.com/watch?v=4Bdc55j80l8)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZU30p5IKezOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelos y tokenizers**\n",
        "\n",
        "Como mencionamos, `pipeline` agrupa tres pasos: preprocesamiento de entradas, paso de las entradas a través del modelo y posprocesamiento.\n",
        "\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg\" width=\"90%\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "zJEGZrJGOPZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocesamiento con un tokenizer**\n",
        "\n",
        "Al igual que otras redes neuronales, los modelos Transformer no pueden procesar texto directamente, por lo que el primer paso de nuestro flujo (pipeline) es convertir las entradas de texto en números comprensibles para el modelo. Para ello, utilizamos un tokenizador, que se encargará de:\n",
        "\n",
        "1. Dividir la entrada en palabras, subpalabras o símbolos (como la puntuación) llamados tokens.\n",
        "2. Asignar un número entero a cada token.\n",
        "3. Agregar entradas adicionales que puedan ser útiles para el modelo.\n",
        "\n",
        "Todo este preprocesamiento debe realizarse de la misma manera que cuando el modelo fue pre-entrenado.\n"
      ],
      "metadata": {
        "id": "nywc9eYPUiay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\""
      ],
      "metadata": {
        "id": "t7vERWu6U0lF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "b3fc626bdd164cab921c17ff9b8444df",
            "367de7a841f64203ae28ab11c958617c",
            "902205e2680846559b4a36c0c8c2fa19",
            "3f23ea40a991451eb2770681f16eff7f",
            "098043635bad4ae084cf8e0f23894d65",
            "5e1f54c2f41241949eca845ecfe8d43d",
            "9e1328f6897545f28f0cbc0c159f44f4",
            "9cdcfd6a11b14a7587aba97f8944d514",
            "239e8cf657d443569a3552f2c2db0407",
            "56eb94e276594de188e09e97ef946454",
            "6a9f5e990c814bdf80137ceb28d2bc78",
            "cd6f315010a9451793d5d350c173cd54",
            "2c63c6874f0149c8b72e9f6170fa34f4",
            "3a679505d4be4d3588dde75c0248394d",
            "2f4ccd66a080449b93aec85b5f256c7a",
            "ec1332ac59f54dd7b9bf699baba9f914",
            "bb9b6372f64d4dc0a296d7ae0ac94c47",
            "ce6492d186164330a79af8bf779e42a7",
            "927af916c17c4ce0a17d9ba147a6841a",
            "c7c4623bea164bb688c24b4fb49dc148",
            "a33524a0f6cd4339a47377ed0d6c080f",
            "d39f03963a504496aa3bb1387ef5e258",
            "99c87ebd03a746519c5c297236c3bf02",
            "830050befd834e7a99ccb0f9f95b79cb",
            "cb6f962c5bde477c8ee2c3a66ef7c7dc",
            "fd406763ad8648fab7860fe2b1d04258",
            "200a725040f14bc789eac0f9a62654f7",
            "f1a2e39b755c4a3dbab973c485abebb0",
            "b09b5ab0fcfe42588cb81824723e440a",
            "ba9d95e0f4b845df8906153d28edbd9b",
            "7f3a52deedc5459aa6ff89746ded0ffe",
            "0078dc3222ca422599eed97de5175da2",
            "5ad11ca9417b47f5a5654e035abf1e58"
          ]
        },
        "id": "Ynn3xWJ3U4ZG",
        "outputId": "383c1da3-5e25-4398-b2d5-6836ed2f1ba9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3fc626bdd164cab921c17ff9b8444df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd6f315010a9451793d5d350c173cd54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99c87ebd03a746519c5c297236c3bf02"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = [\n",
        "    \"I hate when my neighbor does not feed her cat.\",\n",
        "    \"I enjoy coding in Python.\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iXzIB6BU531",
        "outputId": "1c085e23-1d61-4be1-efa0-62dd88cae9a8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  5223,  2043,  2026, 11429,  2515,  2025,  5438,  2014,\n",
            "          4937,  1012,   102],\n",
            "        [  101,  1045,  5959, 16861,  1999, 18750,  1012,   102,     0,     0,\n",
            "             0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La salida en sí es un diccionario que contiene dos claves, `input_ids` y `attention_mask`. `input_ids` contiene dos tensores (de PyTorch) con números enteros (una para cada oración) que son los identificadores únicos de los tokens en cada oración.\n",
        "\n",
        "En cuanto a `attention_mask`, una máscara de atención es una máscara binaria que designa qué tokens deben ser atendidos (asignándoles pesos no nulos) y cuáles deben ser ignorados (asignándoles pesos nulos). Al aplicar esta máscara, el modelo puede atender selectivamente a tokens específicos mientras ignora otros."
      ],
      "metadata": {
        "id": "5RNb-SZVVKUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Procesamiento con el modelo**\n",
        "\n",
        "Ahora podemos descargar un modelo pre-entrenado de la misma manera que lo hicimos con nuestro tokenizador. Para ello, podemos usar el objeto `AutoModel` que también tiene un método `from_pretrained()`:"
      ],
      "metadata": {
        "id": "aC2gRW89YBAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\""
      ],
      "metadata": {
        "id": "uyMDdIAcVbLO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModel.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "X9HAiXdIViTN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta arquitectura contiene solo el módulo base del Transformer: dados algunos inputs, produce lo que llamaremos estados ocultos, también conocidos como características. Para cada input del modelo, recuperaremos un **vector de alta dimensionalidad** que representa la comprensión contextual de ese input por parte del modelo Transformer."
      ],
      "metadata": {
        "id": "TH__Ke9savGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dvVlc3SVk2m",
        "outputId": "317e6fc8-7414-4458-f9cd-094a4c91602d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 13, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **¿Un vector de alta dimensionalidad?**\n",
        "\n",
        "El vector producido por el módulo Transformer suele ser grande. Generalmente tiene tres dimensiones:\n",
        "\n",
        "- **Tamaño del batch:** El número de secuencias procesadas a la vez (2 en nuestro ejemplo).\n",
        "- **Longitud de la secuencia:** La longitud de la representación numérica de la secuencia (13 en este ejemplo).\n",
        "- **Tamaño oculto:** La dimensión del vector de cada input del modelo.\n",
        "Se dice que es \"de alta dimensionalidad\" debido al último valor. El tamaño oculto puede ser muy grande (768 es común para modelos más pequeños, y en modelos más grandes esto puede alcanzar 3072 o más)."
      ],
      "metadata": {
        "id": "LaMco-_5a9dC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Cabezas del modelo**\n",
        "\n",
        "Las cabezas del modelo toman el vector de alta dimensionalidad de estados ocultos como input y los proyectan a una dimensión diferente. Por lo general, están compuestas por una o unas pocas capas lineales:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg\" width=\"90%\">\n",
        "</center>\n",
        "\n",
        "La salida del modelo Transformer se envía directamente a la cabeza del modelo para ser procesada.\n",
        "\n",
        "El modelo está representado por su capa de embeddings y las capas subsiguientes. La capa de embeddings convierte cada ID de input en el input tokenizado en un vector que representa el token asociado. Las capas subsiguientes manipulan esos vectores utilizando el mecanismo de atención para producir la representación final de las oraciones."
      ],
      "metadata": {
        "id": "KZoh6vIEbf4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay muchas arquitecturas diferentes disponibles en Transformers, cada una diseñada para abordar una tarea específica. Aquí hay una lista no exhaustiva:\n",
        "\n",
        "* Model\n",
        "* ForCausalLM\n",
        "* ForMaskedLM\n",
        "* ForMultipleChoice\n",
        "* ForQuestionAnswering\n",
        "* ForSequenceClassification\n",
        "* ForTokenClassification\n",
        "\n",
        "Para nuestro ejemplo, necesitaremos un modelo con una cabeza de clasificación de secuencia (para poder clasificar las oraciones como positivas o negativas). Por lo tanto, en realidad, no usaremos la clase `AutoModel`, sino `AutoModelForSequenceClassification`:"
      ],
      "metadata": {
        "id": "qSfKVP-jgtzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\""
      ],
      "metadata": {
        "id": "yKVQn1lBVptm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "FfA-1gBUVrAj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "print(outputs.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9CTkPT9Vr-n",
        "outputId": "bf73f635-fc57-4c5b-a3e4-7efb114daec2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Pregunta:** ¿Por qué es de 2x2?"
      ],
      "metadata": {
        "id": "Qeajh67NhZoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Postprocesaiento de la salida**"
      ],
      "metadata": {
        "id": "pJjYKjEJhh0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wRTwQtHVwmM",
        "outputId": "800b39dc-44aa-41ca-b860-94a4ffa939b6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.7505, -2.3348],\n",
            "        [-2.4761,  2.5623]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCOGwS64V5bA",
        "outputId": "4805117f-48e8-4dce-b296-6ebddd997c21"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9939, 0.0061],\n",
            "        [0.0064, 0.9936]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctQBoysNV4UM",
        "outputId": "64730cc7-a0be-4953-cfab-d907994f9f07"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Siguientes pasos...**\n",
        "\n",
        "- Preparación de los datos\n",
        "- Fine-tuning de modelos:\n",
        "    - Con la API Trainer\n",
        "    - Con Keras\n",
        "\n",
        "Referencias: https://huggingface.co/learn/nlp-course/en/chapter0/1?fw=pt"
      ],
      "metadata": {
        "id": "QKp_PZ_NDqbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "\n",
        "> Contenido creado por **Rodolfo Ferro**, 2023. <br>\n",
        "> Puedes contactarme a través de Insta ([@rodo_ferro](https://www.instagram.com/rodo_ferro/)) o X ([@rodo_ferro](https://twitter.com/rodo_ferro))."
      ],
      "metadata": {
        "id": "hSdbQU3e6-Ky"
      }
    }
  ]
}